\documentclass[tc,openright]{ii}

\usepackage[T1]{fontenc}        % pacote para conj. de caracteres correto
\usepackage[latin1]{inputenc}   % pacote para acentua\c c\~ ao
\usepackage{graphicx}           % pacote para importar figuras
\usepackage{times}              % pacote para usar fonte Adobe Times
\usepackage{multirow}
%\usepackage{listings}
%\usepackage{scalefnt}
\usepackage{amsmath}
\usepackage[brazilian]{babel}
\usepackage{amsmath}
\usepackage{subfig}
\usepackage{threeparttable}
\usepackage{float}
\usepackage{color}
\usepackage{url}
\usepackage{enumitem}
\restylefloat{table}

\bibliographystyle{abnt}

\hyphenation{en-si-na-men-tos a-gra-de-ci-men-to de-se-nha-dos}


\title{RECONHECIMENTO FACIAL PARA CLASSIFICAÇÃO E REGISTRO DE PRESENÇA EM SALA DE AULA}

\author{Deus}{Alleff Dymytry Pereira de}

\advisor[Profa.~Dra.]{Guimarães}{Letícia Vieira}


% a data deve ser a da defesa; se nao especificada, são gerados
% mes e ano correntes
\date{Janeiro}{2021}

\course{Engenharia de Computação}

\location{Guaíba}{RS}

\keyword{Eigenfaces}
\keyword{Reconhecimento Facial}
\keyword{Haar Like Features}
% inicio do documento
\begin{document}


\maketitle



\begin{folhadeaprovacao}
Monografia sob o título \textit{"Reconhecimento Facial para Classificação e Registro de Presença em Sala de Aula"}, defendida por Alleff Dymytry Pereira de Deus e aprovada em 15 de Janeiro de 2021, em Guaíba, estado do Rio Grande do Sul, pela banca examinadora constituída pelos professores:
    \assinatura{Profa. Dra. Letícia Vieira Guimarães \\ Orientadora}
    \assinatura{Profa. Dra. Adriane Parraga}
    \assinatura{Prof. Dr. João Leonardo Fragoso}
%    \assinatura{Prof. Dr. Roberto Ribeiro Baldino}

\end{folhadeaprovacao}


% dedicatoria
\clearpage
\begin{flushright}
\mbox{}\vfill
{\sffamily\itshape
"Você deve entender que há mais de um caminho para o topo da montanha.''\\}
--- \textsc{Miyamoto Musashi}
\end{flushright}

% agradecimentos
\chapter*{Agradecimentos}
Aos meus familiares por possibilitar que eu pudesse realizar esta etapa dentro de minha vida, podendo dar o melhor de mim do inicio ao fim. Sempre ajudando nos momentos dificies e também nos momentos de alegrias.
\vspace{0.5cm}

À minha noiva, por poder dividir todos os momentos que foram a graduação, sempre me ajudando em situações adversas, sempre aconselhando e dividindo o conhecimento obtido. Ajudando a escalar esta montanha que não é fácil de chegar ao fim.
\vspace{0.5cm}

Aos meus professores, que possibilitaram o conhecimento e o crescimento dos ideais, sempre aconselhando e mostrando os melhores trilhos para seguir nesta jornada.
\vspace{0.5cm}

À Universidade e funcionários que propiciaram um excelente ambiente de aprendizagem, conhecimento e crescimento.

% sumario
\tableofcontents

% lista de abreviaturas e siglas
\begin{listofabbrv}{SPMD}
	\item[PCA] Principal Component Analisys
	\item[ROI] Region Object Interest
\end{listofabbrv}

%lista de símbolos
\begin{listofsymbols}{SPMD}
	\item[$\Gamma$] Vetor unidimensional da Face
	\item[$\Psi$] Face Média do conjunto de faces
	\item[$\Phi$] Face com principais componentes ressaltadas
	\item[$\Omega$] Conjunto de pesos de cada Eigenface para determinada face $\Phi$
	\item[$e_{\Omega}$] Erro das diferenças dos pesos $\Omega$
	\item[$e_{\Phi}$] Erro das diferenças das faces $\Phi$
	\item[$\theta_{\Omega}$] Valor de Threshold dos pesos $\Omega$
	\item[$\theta_{\Phi}$] Valor de Threshold das faces $\Phi$
\end{listofsymbols}

% lista de figuras
\listoffigures

% lista de tabelas
\listoftables

% resumo
\begin{abstract}

Este trabalho tem por objetivo o desenvolvimento de um sistema que detecta faces para o auxílio no registro de alunos presentes no ambiente acadêmico. Para a localização facial será utilizado o método de classificação Haar Like Features e para a classificação das faces encontradas será utilizado o método Eigen Faces. Para  a facilidade de utilização do usuário final, os métodos irão ser integrados em um sistema que possibilita a inclusão dos dados diretamente no banco de dados, possibilitando a consulta dos mesmo com mais agilidade. 

 \end{abstract}

% abstract
\begin{englishabstract}
{Facial Recognition for Classification and Register on Presence in Classroom}
{Eigenfaces,Facial Recognition,Haar Like Features}
(COLOCAR EM INGLES DEPOIS)Este trabalho tem por objetivo o desenvolvimento de um sistema que detecta faces para o auxílio no registro de alunos presentes no ambiente acadêmico. Para a localização facial será utilizado o método de classificação Haar Like Features e para a classificação das faces encontradas será utilizado o método Eigen Faces. Para  a facilidade de utilização do usuário final, os métodos irão ser integrados em um sistema que possibilita a inclusão dos dados diretamente no banco de dados, possibilitando a consulta dos mesmo com mais agilidade.(COLOCAR EM INGLES DEPOIS) 
\end{englishabstract}

\chapter{Introdução}
Nos dias atuais pode-se notar que a biometria é algo amplamente utilizado e ajuda no cotidiano de todas as pessoas, já que pode-se fazer as mais diversas funções, sendo elas: pagamento de contas, liberação para áreas restritas, verificação em e-mails, para direção de um veículo, etc. A biometria tem por base a medição de características humanas de forma analógicas e transforma para o mundo digital, um exemplo de como a utilização da biometria tem sido ampliada é o seu uso no Brasil para operações eleitorais e cada vez mais serão utilizadas tecnologias mais avançadas para os mais diferentes fins, sendo um grande avanço a utilização de reconhecimento facial como biometria.

Segundo a ANSA, no carnaval de 2019, a polícia do Rio de Janeiro e do Salvador, conseguiram detectar e prender criminosos com a ajuda de câmeras equipadas com reconhecimento facial. Existe no mercado atual um crescimento de 20\% até 30\% por ano na área. O reconhecimento facial tem sido debatido para muitos usos, sendo o uso para a segurança pública como um dos usos mais comuns.

O reconhecimento facial pode ser empregado nas mais diferentes áreas, sem ser a da segurança, com isso pode-se empregar o reconhecimento para verificar sentimentos, expressões, executar comandos configurados, check-in em eventos, entre outras aplicações.

%Escrever aqui sobre as outras aplicações de reconhecimento facial.
Com a popularização dos meios de reconhecimento facial, algumas técnicas foram desenvolvidas conforme o tempo e a tecnologia se desenvolveu. Algumas das técnicas que são utilizadas, são elas: Eigenfaces, Fisherfaces, Kernel Direct Discriminant Analysis, K Nearest Neighboors, Local Binary Pattern e etc. As técnicas são utilizadas para os mais diversos fins, ganhando uma popularização muito grande nos últimos dez anos devido ao avanço com a utilização de redes neurais e inteligências artificiais para utilização de tais técnicas.

Com esses avanços nas técnicas de reconhecimento facial, pode-se utilizar tais avanços para o reconhecimento de alunos em sala de aulas, já que os mesmos querem ter seus rostos reconhecidos para obter a presença em sala de aula, fazendo que o método tradicional de folha de chamada posso ser substituído e todo o sistema de presença seja diretamente integrado em um único sistema. E a utilização não precisa ficar somente nas salas de aula, as aplicações podem ser utilizadas para conferir a presença de um indivíduo nos mais diferentes eventos, onde o mesmo que ser reconhecido para obter algum certificado que esteve presente no momento em que foi reconhecido por algum tipo de sistema.

Desta forma, a construção de um sistema de reconhecimento facial integrado com um controle de presença se faz necessário para sanar o problema de ainda hoje, em um tempo de integração e avanço tecnológico, utilizar chamadas impressas para marcar se o aluno estava ou não em aula ou em um determinado evento. Mesmo utilizando alguns recursos tecnológicos como formulários online, ainda precisam que seja encaminhado e preenchidos manualmente para poder se ter a validação.

Com isso o obgetivo geral do presente trabalho é desenvolver um sistema que reconheça um indivíduo e atribua a sua presença em sala de aula ou em eventos, priorizando a portabilidade e facilidade de acesso ao sistema, utilizando a ideia de um sistema que foi previamente pensado na Universidade Estadual do Rio Grande do Sul na unidade de Guaíba, onde o reconhecimento poderia ser feito através do modelo de reconhecimento com Eigenfaces.

\chapter{Fundamentos Teóricos}
Neste capítulo serão abordados os conhecimentos necessários para o entendimento do presente trabalho, bem como seus métodos de desenvolvimento e funcionalidades específicas.

\section{PROCESSAMENTO DIGITAL DE IMAGENS}
Para poder abordar como são feitos os processos sobre as imagens, primeiramente é necessário se fundamentar o que são imagens em um computador.

\subsection{Imagem digital}
Uma imagem pode ser descrita como uma função bidimensional, com dimensões de tamanhos diferentes. As coordenadas da imagem formam um plano e sua amplitude pode ser descrita como a intensidade do conjunto de coordenadas. O valor da função que descreve a imagem é resultado de processos físicos relacionados a energia irradiada pela fonte. Uma imagem pode ser captada a partir de sensores que conseguem traduzir a energia irradiada pela fonte em valor de tensão. Segundo \cite{Gonza}, um dos sensores mais conhecidos para tal utilização, são os fotodiodos, sendo estes sensores construídos com materiais semicondutores que possuem uma saída de tensão proporcional a intensidade luminosa. Entretanto, a imagem digital tem valores dos elementos de coordenadas e amplitude finitas. Os elementos que compõem uma imagem digital são chamados de \textit{Pixels}.

\subsection{Processamento Digital}
A imagem digital, pode ser processada por um sistema computacional de forma que pode-se abordar que o processamento digital de imagens sendo a área que utiliza imagens como entrada principal com diversos propósitos, por exemplo, realçar certas características de objetos na imagem. O processamento de imagem apresenta como saída uma nova imagem. Contudo alguns autores consideram certas operações como sendo parte da visão computacional, já que o precessamento é apontado como uma função que recebe uma imagem e retorna uma imagem. Todavia, funções como obtenção e classificação de informações nas imagens são consideradas parte da visão computacional e análise de imagens. Segundo \citep{Gonza}, não existem limites claros onde se pode considerar que uma operação faz parte de qual linha de pesquisa, o que se pode traçar é um paradigma que utiliza três níveis de operações, sendo eles: o nível de processo baixo, médio e alto. O nível de processamento baixo é constituído de pré-processamentos e as mais diversas operações primitivas que se pode fazer com uma imagem. O nível de processo médio constitui-se com tarefas de segmentação de ROIs, descrição para a posterior utilização na classificação dos objetos segmentados. E o nível de processo alto seria a área que atribui um sentido lógico e real para as informações adquiridas pelos dois níveis inferiores. 

\section{CARACTERÍSTICAS DO TIPO HAAR}
As características do tipo Haar ou (Haar Like Features) são características baseadas nos Haar wavelets desenvolvidas por Alfred Haar, onde transforma um sinal em uma representação mais simples para certos procedimentos de análise. Primeiramente desenvolvido por \cite{viola}, são características utilizadas para o reconhecimento de objetos (neste caso o reconhecimento de faces). As características utilizadas para o reconhecimento se baseiam no cálculo da diferença entre os pixels dentro de uma região retangular, essas características são divididas em três: 1) diferença entre dois retângulos, tanto verticais como horizontais; 2) diferença entre três retângulos, considerando a soma dos retângulos das bordas com a diferença do retângulo central e; 3) diferença diagonal de pares de retângulos, um exemplo dessas características pode ser notado na Figura \ref{haar}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{figuras/haar.png}
	\caption{Exemplos de região retangular para análise de características do tipo Haar.}
	\label{haar}
\end{figure}

\section{ANÁLISE DE COMPONENTES PRINCIPAIS}
A Análise de Componentes Principais (Principal Component Analysis - PCA) é uma técnica matemática utilizada para a análise de dados de para sistemas com múltiplas variáveis. Primeiramente concebido por Karl Pearson em 1901 e posteriormente desenvolvida por Harold Hotelling em 1930. O PCA não era utilizado tão comumente até os avanços na área da computação. Este método se baseia na utilização de princípios matemáticos para transformar um número de variáveis correlacionais em quantidades menores de variáveis, sendo estas as principais componentes das variáveis.A principal transformação é a redução da dimensionalidade do conjunto de dados, fazendo com que sejam ressaltadas as similaridades e diferenças dentro do conjunto de dados. Segundo \cite{pca} os autovetores e autovalores são os princípios fundamentais para a determinação dos PCAs, decorrido da decomposição da matriz de covariância. O processo de obtenção dos PCAs pode ser feito através dos seguintes passos:

\begin{itemize}
\item \textbf{Subtração da Média} 
\end{itemize}

Para que o cálculo do PCA funcione devidamente, é necessário realizar a subtração do conjunto dos dados de sua média em ambos os eixos, para que possa ser produzido uma média dos dados de valor zero;

\begin{itemize}[resume]
\item \textbf{Cálculo da Matriz de Covariância} 
\end{itemize}

É necessário obter a matriz de covariância do conjunto de dados que já foram subtraídos da média, podendo se obter o valor de covariância através da Eq. \ref{covariancia}, onde $x_i$ e $y_i$ são pontos de um vetor de tamanho $n$ e $x^{\prime}$ e $y^{\prime}$ são os valores médios de cada vetor. A matriz de covariância é a junção da covariância de cada objeto das dimensões das variáveis, este cálculo pode ser notado na Eq. \ref{mat_cov}, onde $x$ e $y$ são coordenadas dos vetores $X$ e $Y$;

\begin{equation}
	\label{covariancia}
	cov(x,y) = \dfrac{1}{n} \sum \limits _{i=1}^{n} (x_i - x^{\prime})(y_i - y^{\prime})
\end{equation}

\begin{equation}
	\label{mat_cov}
	cov(X,Y) = \left[ \begin{array}{c c c c}
				 cov(x_{1},y_{1}) & cov(x_{1},y_{2}) & \cdots & cov(x_{1},y_{n}) \\
				 cov(x_{2},y_{1}) & cov(x_{2},y_{2}) & \cdots & cov(x_{2},y_{n}) \\
				 \vdots & \vdots & \cdots & \vdots \\
				 cov(x_{n},y_{1}) & cov(x_{n},y_{2}) & \cdots & cov(x_{n},y_{n}) \\
			\end{array} \right]         	 
\end{equation}

\begin{itemize}[resume]
\item \textbf{Cálculo dos autovetores e autovalores} 
\end{itemize}

Existem várias formas de se calcular os autovetores e autovalores, uma delas é descrita pela Eq.\ref{eigenvec}.

\begin{equation}
	\label{eigenvec}
	(A - \lambda I)u = 0
\end{equation}

Onde 'A' é uma matriz conhecida, '$\lambda$' é o autovalor de 'A' , 'u' são os autovalores de 'A' e 'I' é a matriz identidade;

\begin{itemize}[resume]
\item \textbf{Escolher as componentes} 
\end{itemize}

Deve-se escolher os maiores autovalores dos quais serão obtidos os maiores autovetores como consequência, sendo estes os valores que mais representam as componentes principais do conjunto de dados.

Ainda, segundo \cite{pca}, o PCA pode ser considerado como a projeção do conjunto de dados em uma direção do espaço onde os dados têm uma grande variação, onde a direção é dada pelos autovetores da matriz de covariância correspondendo aos maiores autovalores.

\section{EIGENFACES}\label{r1}
Os eigenfaces é um dos modelos de representação das faces utilizados em algoritmos de reconhecimento facial. O Eigenfaces consiste na obtenção de autovetores que melhor representam (uma representação matamética generalizada de uma face) a face de cada indivíduo. A utilização do termo \textit{Eigenface} foi apresentado por \cite{turk2}. Neste artigo os autores definem "faces fantasmas" que possuem os maiores autovetores e autovalores do PCA do conjunto de dados. Segundo \cite{turk2} a ideia de  utilizar eigenfaces foi motivado na pesquisa de \cite{kirby}, que utilizavam as melhores coordenadas para representar uma face, sendo denominado de \textit{Eigenpictures}. Com isso podia-se reconhecer uma face com uma pequena componente \cite{kirby} , utilizava-se a parte dos olhos para se fazer o reconhecimento, contudo, a ideia de utilizar uma pequena quantidade de características diferentes para reconhecer cada indivíduo persistiu, formando (produzindo) assim uma Eigenface. Desta forma eigenfaces são produzidas multiplicando um conjunto de PCAs da face de cada indivíduo pelos maiores autovetores da matriz de covariância.
%é feito por meio da obtenção das PCAs da face de cada indivíduo de um conjunto de imagens previamente separado, onde os melhores eigenvectors serão a projeção dessas faces no conjunto de componentes denominado "espaço de faces". 
 
\subsection{Reconhecimento Utilizando Eigenfaces}

Pode-se utilizar eigenfaces para reconhecimento facial, alguns passos devem ser feitos antes do reconhecimento concreto, levando em consideração que as imagens utilizadas estão centralizadas e possuem os mesmos tamanhos. Sendo assim pode-se dividir o processo em duas etapas, a primiera de treinamento e o segundo de reconhecimento. Para a etapa de treinamento os seguintes passos devem ser feitos:

\begin{itemize}

\item Adquirir uma coletânea de imagens para ser o conjunto de treinamento;
\item Deixar as imagens no tamanho desejado, cortando somente a face como objeto de interesse;
\item Transformar o vetor de imagens I ($I = N \times N$) em um vetor gamma $\Gamma$ ($\Gamma = N^{2} \times 1$);
\item Calcular a face média $\Psi$ do vetor $\Gamma$;
\item Obter a matriz de covariância $C$;
\item Obter os autovalores e autovetores da matriz de Covariância $C$;
\item Selecionar os melhores M eigenvectors; 
\item Manter somente os K melhores autovetores (K com maiores autovalores);%Treshold
\item Calcular os pesos $\Omega$ de cada face $\Phi$ pelas eigenfaces.

\end{itemize}

A segunda etapa sendo a de reconhecimento, se utiliza uma face que esta fora do conjunto de treinamento para poder fazer a validação, além de que deve estar com o mesmo tamanho das imagens do conjunto de treino, seguindo os seguintes passos:

\begin{itemize}

\item Normalizar a imagem de teste $\Phi = \Gamma - \Psi$
\item Calcular pesos $\Omega$ da imagem de teste pelas eigenfaces do conjunto de treinamento;
\item Determinar se a imagem de entrada é uma face pertencente ao conjunto de treinamento pela distância Euclidiana;

\end{itemize}

\section{SISTEMAS EMBARCADOS}\label{r2}
Atualmente as tecnologias de microeletrônica e de computação estão cada vez mais com maior capacidade, além de tornarem-se mais populares e acessíveis. Sendo assim encontram-se diversos tipos diferentes de tecnologias para os mais diversos fins.
%sendo assim um conceito para que essas tecnologias possam ser classificadas e separadas para os seus específicos fins, pode-se utilizar o conceito de sistemas embarcados. 
Os sistemas embarcados são tecnologias que são construídas para devidos fins específicos com hardware (circuítos e componentes eletrônicos) específico que acaba não podendo ser reutilizado em outras aplicações que não possuam o mesmo hardware utilizado em seu desenvolvimento original.

Os sistemas embarcados podem normalmente desempenhar processos simples, que não geram nenhum tipo de risco para os usuários (exemplo de calculadoras, controles de videogames, telefones, etc.), contudo também podem ser utilizados para tarefas mais complexas que apresentam certos riscos se não forem projetados com um maior rigor (exemplo controle em aviões, controles industriais, monitoramento de saúde, etc.).

Neste âmbito um sistema desenvolvido para um hardware específico pode ser considerado um sistema embarcado, neste tipo de aplicação um hardware muito utilizado atualmente são as RaspberryPi, que são microprocessadores que rodam sistemas operacionais de diversos tipos.


%\begin{equation}
%N = 300
%\end{equation}
%\begin{equation}
%N^2 = 90000
%\end{equation}
%\begin{equation}
%M = 196
%\end{equation}
%\begin{equation}
%K = 50
%\end{equation}
%\begin{equation}
%I \rightarrow N \times N
%\end{equation}
%\begin{equation}
%\Gamma \rightarrow N^2 \times 1
%\end{equation}
%\begin{equation}
%\Psi \rightarrow N^2 \times 1
%\end{equation}
%\begin{equation}
%\Phi_i \rightarrow N^2 \times 1
%\end{equation}
%\begin{equation}
%C \rightarrow N^2 \times N^2
%\end{equation}
%\begin{equation}
%A \rightarrow M \times N^2
%\end{equation}
%\begin{equation}
%C_{mod} \rightarrow M \times M
%\end{equation}
%\begin{equation}
%u \rightarrow M \times N^2
%\end{equation}
%\begin{equation}
%w_i \rightarrow 1 \times 1
%\end{equation}
%\begin{equation}
%\Omega_i \rightarrow K \times 1
%\end{equation}
%\begin{equation}
%\Omega_i = \lceil w_1 \rceil \\ \vert w_2 \vert
%\end{equation}

\chapter{Materiais e métodos}
Neste capítulo serão abordados os materiais e os métodos utilizados para a construção e desenvolvimento do presente trabalho.
%Já estava escrito
O desenvolvimento do presente trabalho possuí uma construção paralela das funções para que se possa ser integrado cada parte do sistema, afim de chegar no final do desenvolvimento com todas as funções funcionando integralmente, sendo assim o início do desenvolvimento segue a etapa de aquisição das imagens, tendo em paralelo o desenvolvimento de uma interface que seja de simples acesso e o mais claro possível para o usuário final.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{figuras/diagrama.jpg}
	\caption{Diagrama das etapas de desenvolvimento.}
	\label{diagrama}
\end{figure}

%Estou adicionando agora para modificar para o segmento de duas partes do sistema
O desenvolvimento do presente trabalho foi dividido em duas partes seguindo o modelo de metodologia da Figura \ref{diagrama}, sendo agrupadas em relação aos processos necessários para o funcionamento das funções desenvolvidas, sendo assim pode-se dividir entre o processo de supervisão do sistema e o processo de atribuição da presença do aluno. Algumas funções possuem características em comum, mudando somente a utilização final de seus resultados, como pode ser notado na Figura \ref{proc_super} e \ref{proc_atrib}. O processo de supervisão do sistema tem por objetivo conter todas as funções que somente o administrador do sistema poderá utilizar. O processo de atribuição de presença do aluno ocorre automaticamente dentro do sistema, sendo necessário ao administrador analisar os logs do sistema para caso seja necessário ajustar ou inserir o aluno na base de dados.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.2\textwidth]{figuras/proc_super.jpg}
	\caption{Diagrama do processo de supervisão do sistema.}
	\label{proc_super}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.2\textwidth]{figuras/proc_atrib.jpg}
	\caption{Diagrama das etapas de desenvolvimento.}
	\label{proc_atrib}
\end{figure}

A aplicação foi desenvolvida utilizando a linguagem de programação Python, sendo esta uma linguagem de programação considerada de alto nível, tendo o seu funcionamento interpretado, onde o programa é executado por um interpretador e após pelo sistema operacional ou processador. A linguagem também é orientada a objetos e funcional. Foi criada em 1991. Possui uma grande comunidade, já que a linguagem possui um modelo de desenvolvimento comunitário, onde várias pessoas podem ajudar a desenvolver novas bibliotecas para que toda a comunidade posso utilizar. O sistema proposto foi desenvolvido e testado em uma máquina que possui um processador AMD Ryzen 5 3400G de 3,7GHz, memória RAM de 16GB e uma placa de vídeo Radeon RX 590 de 8GB de VRAM, mas para a aplicação final será utilizado em uma Raspberry Pi 3, que possui um processador ARMv8 CORTEX A53 QUADCORE com velocidade de operação de 1.2GHz e 1GB de memória RAM. Utilizando o sistema operacional Linux para executar a aplicação desenvolvida.

As imagens utilizadas para o treinamento no presente trabalho foram retiradas do banco de imagens FEI face database, sendo este um banco de imagens desenvolvido pelo Laboratório de Processamento de Imagens do Departamento de Engenharia Elétrica do Centro Universitário da FEI. Esse banco contém 14 imagens diferentes de 200 indivíduos diferentes, obtendo um total de 2800 imagens. Dos 200 indivíduos pertencentes ao banco, para o treinamento do presente trabalho somente 49 indivíduos foram utilizados, sendo 1/4 do valor total. As imagens do banco de faces possuem uma diversidade de indivíduos, tendo diferenças de idade, diferenças de sexo, diferenças de etnias e etc, com isso é possível gerar uma diversidade de PCAs. Segundo \cite{turk2}, existem problemas significantes de se possuir fundo nas imagens das faces, já que as eigenfaces não fazem distinção do que é ou não uma face. Sendo assim deste banco somente as imagens de face frontal foram utilizadas para o formar um conjunto de treinamento e teste. Sendo assim é necessário recortar somente o rosto de cada indivíduo. 

Neste trabalho o processo de reconhecimento facial segue os processos básicos para o reconhecimento, tendo somente a modificação de inserção dos dados obtidos no banco de dados, esta ordem pode ser notada na figura \ref{aquisicao}.

\begin{figure}[htb]
   \centering
   \includegraphics[width=0.8\textwidth]{figuras/metodologia2.jpg}
   \caption{Esquemático do método de classificação.}
   \label{aquisicao}
\end{figure}

\begin{itemize}
\item AQUISIÇÃO: O processo de aquisição se refere ao momento em que o usuário tem sua face adquirida por um dispositivo de captura (câmera, filmadora, webcam, etc.);

\item ROI: O processo de determinação de região de interesse tem por funcionamento encontrar uma face na imagem adquirida no processo anterior;

\item SEGMENTAÇÃO: O processo de segmentação por sua vez retira para o sistema somente a face localizada no processo anterior, facilitando a próxima etapa do sistema;

\item CLASSIFICAÇÃO: O processo de classificação consiste em utilizar a face para o reconhecimento de qual usuário está no sistema;

\item INSERÇÃO: O processo de inserção finaliza o sistema, inserindo qual usuário que foi reconhecido pelos processos anteriores.
\end{itemize}

Cada fase do reconhecimento facial tem uma parte dentro do sistema que executa uma função necessária para poder obter as informações necessária para conseguir obter um valor(face) aceitável para o reconhecimento.

\section{Aquisição da Imagem}
Para a aquisição da imagem dentro do sistema é necessário a utilização de imagens adquiridas a partir de uma webcam para captura, para ser feito o acesso a webcam a biblioteca OpenCV foi utilizada, sendo o OpenCV uma biblioteca de visão computacional e aprendizagem de máquina com código livre, possuindo mais 2500 algoritmos otimizados para uso de todos. Os algoritmos vão desde detectar objetos até extração de modelos 3D. A biblioteca pode ser utilizada nas linguagens de programação Python, C++, Java e MatLab, tendo seus códigos escritos nativamente em C++. Com a utilização do OpenCV pode-se utilizar diversos tamanhos de imagens diferentes, no presente trabalho foi utilizado as seguintes dimensões: Altura - 480 pixels e Largura - 640 pixels, poderia se utilizar o tamanho da imagem necessária para a obtenção das eigenfaces diretamente, contudo se perderia resolução no momento de aquisição da imagem, reduzindo a chance de reconhecimento das eigenfaces.

\begin{itemize}
\item Aquisição na Supervisão do Sistema
\end{itemize}
A aquisição da imagem durante a supervisão do sistema ocorre de forma a se obter imagens para cadastrar um novo aluno ou alterar uma imagem já existente. Sendo assim o administrador do sistema pode adquirir uma imagem quando achar necessário, durante a aquisição o processo de salvar uma imagem só pode ser feito se uma face for encontrada pelas características haar, como na Figura \ref{segmentacao}, caso não seja detectado uma face o sistema não permite que seja adquirido uma imagem, assim protejendo o sistema de possíveis falhas. 

\begin{itemize}[resume]
\item Aquisição na Atribuição da presença
\end{itemize}
A aquisição da imagem durante o processo de atribuição da presença ocorre automaticamente, onde assim que uma face é encontrada, a imagem da mesma é adquirida e disponibilizada para o sistema, sem a supervisão de um usuário. A imagem adquirida é disponibilizada por um curto período de tempo para que o indivíduo possa ver que seu rosto foi adquirido pelo sistema e sua presença registrada.

\section{Segmentação Facial}
Para se obter somente a face de cada indivíduo, foi utilizado o Haar Like feature para faces frontais e realizar um processamento na imagem para se obter somente um único canal de escala de cinza (as imagens originais possuem três canais RGB), este tratamento e manuseio das imagens é feito utilizando o OpenCV. A segmentação das faces é dividida em duas situações:

\begin{itemize}
\item Segmentação na Supervisão do Sistema
\end{itemize}

A segmentação da face na supervisão do sistema utiliza as faces adquiridas previamente pelo administrador do sistema, sendo processadas utilizando as características haar para retirar somente a face frontal sendo esta a região de interesse. As faces segmentadas passam por um processamento para somente possuir um canal em escala de cinza, assim elas podem ser utilizadas para os cálculos necessários no sistema.

\begin{itemize}[resume]
\item Segmentação na Atribuição de presença
\end{itemize}

A segmentação da face durante a atribuição da presença, utiliza a face adquirida pelo sistema a partir da webcam, segmentando a face utilizando as características haar como na supervisão do sistema, contudo este processo ocorre sem que o administrador precise ter interação com o sistema. A face segmentada é encaminhada para as próximas funções necessárias para a atribuição da presença, um exemplo da segmentação na interface pode ser notado na Figura \ref{segmentacao}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{figuras/segmentacao.jpg}
	\caption{Segmentação Facial.}
	\label{segmentacao}
\end{figure}

\section{Obtenção Eigenfaces}
Para os cálculos de obtenção da eigenfaces a biblioteca Numpy foi utilizada, sendo esta uma biblioteca de código aberto que consegue processar os mais diversos tipos de processos de computação numérica. Criada em 2005 e utilizada amplamente na comunidade científica para os mais diversos cálculos matemáticos e manipulação de dados.

Para os cálculos das eigenfaces deve-se considerar o tamanho das imagens que serão utilizadas no sistema, sendo assim, tanto as imagens do banco de faces e as imagens adquiridas pela webcam foram redimensionadas no tamanho $N = 300$ e possuem somente um canal em escala de cinza para a minimização dos cálculos (Imagem sem modificar $I: (N \times N \times 3)$, imagem modificada $I: (N \times N \times 1)$)  após deve-se transformar cada imagem $I : (N \times N)$ em um vetor gama $\Gamma : (N^2 \times 1)$, onde é necessário tranformar o vetor em uma dimensão, um exemplo da imagem de treinamento pode ser vista na figura \ref{face}. As imagens podem ser normalizadas dividindo pelo valor máximo de 255 para facilitar os cálculos.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{figuras/faces.jpg}
	\caption{Faces sem tratamento pertencentes ao treino.}
	\label{faces}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.4\textwidth]{figuras/face1.jpg}
	\caption{Face tratada pertencente ao treino.}
	\label{face}
\end{figure}

Após este processo de achatamento da imagem, deve-se obter a face média do treinamento, sendo uma soma de todas as imagens presentes no treinamento e dividido pela quantidade de imagens, sendo obtida uma imagem $\Psi$ na equação \ref{psi}.

\begin{equation}
\Psi = \dfrac{1}{M} \sum \limits _{i=1}^{M} \Gamma_i
\label{psi}
\end{equation}

A imagem gerada é um amalgama de todas as faces de treino, possuindo um pouco de cada característica mais exuberante de cada face, o resultado da junção das faces pode ser notada na figura \ref{psi_face}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.4\textwidth]{figuras/psi.jpg}
	\caption{Face média $\Psi$.}
	\label{psi_face}
\end{figure}

Cada face $\Gamma$ pode ser subtraida da face média $\Psi$ para assim formar um vetor de diferenças $\Phi$ presente na equação \ref{phi}, sendo estas as diferenças mais distintas de cada face, essa diferença pode ser notada nas figura \ref{phi_face}.

\begin{equation}
\Phi_i = \Gamma_i - \Psi
\label{phi}
\end{equation}
 
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.45\textwidth]{figuras/phi.jpg}
	\caption{Faces $\Phi$.}
	\label{phi_face}
\end{figure} 
 
Os autovetores e autovalores podem ser obtidas a partir da matriz de covarância do vetor $AA^T$ como pode ser visto na equação \ref{cov}, sendo este um vetor de $\Phi$, porém esta matriz possui um tamanho que pode ser um disperdicio computacional ($N^2 \times N^2$) então é necessário fazer o cálculo a partir da matriz transposta $A^T$ que é computacionalmente menor ($M \times M$). 

\begin{equation}
\label{cov}
	C = \dfrac{1}{M} \sum \limits _{i=1}^{M} \Phi_i\Phi_{i}^{T} = AA^T \hspace{1cm}(N^2 \times N^2)
\end{equation}

Sendo assim é necessário calcular os autovetores a partir de $A^T A$ e achar os autovetores de $AA^T$ a partir da relação da equação \ref{egvec}.

\begin{equation}
A^TAv_i = \mu_i v_i \Rightarrow
AA^TAv_i = \mu_i Av_i \Rightarrow
CAv_i = \mu_i Av_i \Rightarrow
onde\longrightarrow u_i = Av_i
\label{egvec}
\end{equation}

Sendo assim é possível encontrar os autovetores da matriz de covariância $AA^T$, sendo estes os maiores autovetores de dos autovetores de $A^T A$. Os autovetores podem ser referenciados como as eigenfaces que devem ser redimensionadas para que seja possível ser visualizadas em uma imagem. Alguns exemplos de eigenfaces obtidas podem ser vistas na figura \ref{eigenface}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.45\textwidth]{figuras/eigen.jpg}
	\caption{Eigenfaces.}
	\label{eigenface}
\end{figure}

Com as eigenfaces geradas é necessário calcular os pesos de cada eigenface nas diferentes faces do treinamento, os pesos calculados para cada face são obtidos utilizando as eigenfaces transpostas vezes a face $\Phi$ como na equação \ref{weigth}. Durante a fase de supervisão do sistema, após os pesos $\Omega$ serem gerados, os mesmos são salvos no banco de dados já que durante a fase de atribuição da presença somente é necessário o cálculo dos pesos $\Omega$ da face adquirida.

\begin{equation}
\label{weigth}
	w_j = u_{j}^{T}\Phi_i
\end{equation}

Os pesos $w_j$ são distintos para cada face, a soma dos pesos mais a face média $\Psi$, resulta na face original $\Phi$, contudo essa reconstrução pode não ocorrer do jeito esperado, já que cada rosto possui uma forma própria mesmo que elas sejam alinhadas. Para representar as faces no "espaço de faces" é necessário reunir cada peso $w_j$ de cada face em um vetor $\Omega$ como na equação \ref{Omega}

\begin{equation}
\label{Omega}
	\Omega_i = \left[ \begin{array}{c}
				 w_{1}^{i} \\ w_{2}^{i} \\ w_{3}^{i} \\ \vdots \\ w_{K}^{i} 
			\end{array} \right], \hspace{2cm} i = 1,2,\cdots,M	 
\end{equation}


%Assim com as imagens previamente tratadas, é necessário calcular a imagem da face média $\Psi$, sendo este o valor médio do vetor $\Gamma$. Após este cálculo é necessário fazer a diferença da face média $\Psi$ com o vetor $\Gamma$ gerando o vetor de componentes principais $\Phi$, com isso é possível calcular a matriz de covariância e seus autovalores e autovetores. Os maiores autovetores da matriz de covariância são as eigenfaces do sistema. Um processo que serve para o reconhecimento é o cálculo dos pesos referentes as eigenfaces, esses pesos são colocados em um vetor $\Omega$.

\section{Classificação Eigenfaces}
O processo de classificação utilizando eigenfaces somente é necessário na atribuição das presenças, já que para este atribuição a face do indivíduo deve ser reconhecida. Com isso para os cálculos e processos para classificação das eigenfaces, a biblioteca Numpy foi utilizada. As imagens obtidas previamente são tratadas como vetores numéricos, para poder ser utilizado pela Numpy. Com isso é necessário obter a nova imagem para teste e refazer todos os processos anteriores para normalizar (segmentar a face da imagem, tranformar em um canal de escala de cinza, transformar em um vetor $\Gamma$) a imagem para estar igualmente com as imgens do conjunto de treinamento. A nova face não possui os pesos calculados em relação as eigenfaces do sistema, sendo assim é necessário fazer este cálculo dos pesos $\Omega$ para fazer o reconhecimento se a face pertence ou não ao sistema. Este processo é uma  representação da face nova, de fora do conjunto de treinamento, no "espaço de faces" normalizando ela com a face média $\Psi$ como na equação \ref{new_face} (a nova face já deve estar no formato de $\Gamma$ para ser representada).

\begin{equation}
\label{new_face}
	\widehat{\Phi} = \Gamma - \Psi
\end{equation}

Para a projeção das eigenfaces é necessário calcular o vetor de pesos $\Omega$ desta face $\Gamma$, utilizando as eigenfaces obtidas anteriormente, essa representação pode ser vista na equação \ref{project_face}

\begin{equation}
\label{project_face}
	 w_i = u_{i}^{T}\widehat{\Phi} \hspace{2cm}
	 \Omega = \left[ \begin{array}{c}
				 w_{1} \\ w_{2} \\ w_{3} \\ \vdots \\ w_{K} 
			\end{array} \right]
\end{equation}

Calculando o vetor $\Omega$ da nova face, é necessário achar o menor erro euclidiano entre os pesos da nova face menos os pesos de cada face do conjunto de treinamento. Este erro deve ser o menor possível e estar abaixo de um valor de \textit{threshold} para ser considerado a mesma face, a equação \ref{error} representa essa distância da face nova de cada face do conjunto de treino.

\begin{equation}
\label{error}
	e_{\Omega} = min_l \hspace{1mm} \| \Omega - \Omega^l \| 
\end{equation}

O valor de \textit{Threshold} pode ser escolhido arbitrário ou perante um critério de cada aplicação, segundo \cite{marijeta}, não há uma formula para o cálculo de um valor de \textit{Threshold},o que se pode fazer é calcular o erro mínimo da imagem de teste com o treinamento, obtido a partir da fórmula \ref{error}, e pode-se calcular utilizando a equação \ref{thresh}. Contudo este valor máximo acaba sendo um valor distante dos demais valores de erros da fórmula \ref{error}, não podendo ser utilizado para a comparação.

\begin{equation}
\label{thresh}
	\theta = 0,8 * max(rast) 
\end{equation}

Para o reconhecimento de uma face, as seguintes considerações foram feitas utilizando os valores de \textit{Threshold} obtidos a partir de experimentação:
\begin{itemize}
\item Se o menor valor de $e_{\Omega}$ < $\theta_{\Omega}$ a face pode pertencer ao sistema;
\item Se o menor valor de $e_{\Phi}$ < $\theta_{\Phi}$ a face é pertencente ao sistema;
\item Se o valor de $e_{\Omega}$ considera uma face diferente de $e_{\Phi}$, o valor de $e_{\Phi}$ é levado em consideração;
\item Se o menor valor de $e_{\Omega}$ >= $\theta_{\Omega}$ a face não pertencer ao sistema;
\end{itemize}

As faces que são reconhecidas como não pertencentes ao sistema, podem ser adicionadas posteriormente ao sistema, recalculando a face $\Psi$ e as eigenfaces com esta face nova.

\section{Desenvolvimento da Interface}
A interface do sistema foi desenvolvida utilizando a biblioteca Tkinter, sendo esta uma das bibliotecas padrões para desenvolvimento de insterfaces, possui integração com a maioria dos sistemas operacionais Unix e Windows, fazendo com que seja possível possuir uma interface compatível com uma grande gama de sistemas operacionais. A interface pode ser dividida dentro dos dois processos que o presente trabalho foi dividido.

\begin{enumerate}
\item Supervisão do Sistema
\end{enumerate}

A interface da Supervisão do Sistema possui o intuito de manter as funções necessárias para o funcionamento correto do sistema podendo ser acessado somente pelo administrador do sistema, devido ser necessário fazer um login de acesso a esta tela, com isto nesta parte do sistema pode-se cadastrar novas faces ao banco de faces, cadastrar novos aula/eventos, verificar os estados das presenças.

\begin{itemize}
\item Cadastro de faces
\end{itemize}

Dentro da fase do reconhecimento facial, existe a possibilidade que uma face não seja reconhecida como pertencente ao sistema, sendo assim se faz necessário cadastrar o indíduo no sistema, sendo assim a função para cadastro de novas faces possibilita a aquisição das imagens da face diretamente a partir da webcam integrada ao sistema, sendo necessário obter um segmento de imagens e escolher a melhor entre elas. A imagem escolhida passa por um processo de normalização, para ser armazenada no banco de dados junto com as suas informações.

Devido ao cadastro de uma nova face ao banco de faces, se faz necessário recalcular a face $\Psi$ juntamente com os pesos $\Omega$ da conjunto de treinamento, o conjunto de treinamento é composto de todas as faces do sistema, onde é necessário sempre fazer os cálculos previamente para a utilização no reconhecimento, após os cálculos é necessário atualizar as informações no banco de dados e no Google drive.

\begin{itemize}[resume]
\item Cadastro de aulas e eventos
\end{itemize}

Com o reconhecimento da face de um indivíduo, deve-se colocar a sua presença em uma tabela que posteriormente é armazenada no banco de dados, assim é necessário que o administrador do sistema cadastre os eventos e aulas previamente, nesta parte do sistema o admnistrador pode colocar o nome da aula e do evento, a data.

\begin{itemize}[resume]
\item Verificar presença
\end{itemize}

Como existe a possibilidade de um indivíduo não estar cadastrado no sistema ou acabar sendo confundido com outro indivíduo, o administrador do sistema pode  ver e analisar os logs do sistema no momento em que a presença foi assinalada ao indivíduo. Dentro desta análise é possível para o administrador cadastrar um novo indivíduo, já que dentro do log do indivíduo que não foi reconhecido possui anexado a imagem do mesmo.

\begin{enumerate}[resume]
\item Atribuição de presença
\end{enumerate}

A tela de atribuição de presença pode ser considerado como a tela principal do sistema, devido este tela ser executada na meioria do tempo em contrapartida da tela de configuração. Nesta parte do sistema são utilizadas as funções de aquisição das imagens, processamento da imagem adiquirida, reconhecimento e cadastro da presença.

A interface possui em sua tela principal a visualização da visão da câmera integrada ao sistema, quando uma face é encontrada pelo sistema, a mesma é resaltada na tela principal além das informações do indivíduo da qual a face o sistema reconheceu.


\section{Integração Banco de Dados}
Dentro do desenvolvimento do trabalho proposto, foi necessário criar um meio de armazenar e recuperar as imagens e valores utilizados pelo sistema. No inicio da aplicação foram utilizadas as imagens localmente, sendo armazenadas e utilizadas somente durante a execução do sistema. Contudo este tipo de solução pode acabar esgotando o armazenamento interno do dispositivo que roda o sistema, sendo assim para que este problema fosse sanado, a forma de armazenamento das informações foi dividdo em duas formas, sendo uma delas para o armazenamento das informações e outra para o armazenamento dos arquivos.

As imagens que são utilizadas pelo sistema projetado deve ser alocado em um local que seja fácil buscar e armazenar, sendo assim foi pensado em utilizar um banco que tivesse uma liberdade de inserir as informações das imagens sem a necessidade de um banco complexo. Sendo assim o banco de dados MongoDB foi tutilizado, sendo o MongoDB um banco de dados não relacional que utiliza documentos para armazenar informações, utilizando informações na linguagem JSON. Podendo se conectar com as mais diversas linguagens de programação (como por exemplo: Java, Python, Ruby, C++, etc). Pode ser utilizado com repositórios locais ou até mesmo com repositórios armazenados em nuvem de forma gratuita (conforme utilização do armazenamento e acesso repetidos dos dados). Dentro de algumas de suas vantegens, pode-se elencar a relação de não ser necessário as condições relacionais para começar a armazenar dados, obtendo melhor performace em relação as suas consultas, já que tudo esta dentro de um único documento. Contudo isso acaba sendo uma desvantagem também, pois caso seja necessário a modificação de algum atributo para todos as entradas, cada valor deve ser tratado um a um. Devido a quantidade de arquivos que são necessários para o funcionamento do projeto, as informações dos arquivos foram salvos no MongoDB e os arquivos propriamente ditos foram armazenados no Google Drive, sendo este um serviço de armazenamento e sicronização de arquivos desenvolvido pela empresa Google.

Para o acesso de ambos os bancos é necessário a configuração e utilização de arquivos de configuração, que contenham os usuários e senhas para acesso. Para o acesso do repositório do MongoDB é necessário repassar a linha de conexão do repositório. Para a conexão do Google Drive é necessário a configuração e o aceite na conta do usuário que irá hospedar os arquivos, neste caso foi configurado o arquivo \textit{settings.yaml} para que não fosse necessário abrir uma janela de aceite a cada vez que o sistema fosse executado.

Para o armazenamento das informações no MongoDB, o seu acesso é feito a partir da biblioteca \textit{Pymongo}, onde cada face tem as seguintes informações armazenadas: 
\begin{itemize}
\item ID do Mongo;
\item Nome da Pessoa;
\item ID do Google Drive.
\end{itemize}

O \textit{ID do Mongo} é um identificador que é gerado automaticamente, sendo uma chave primária igual a de um banco de dados relacional, onde este é um identificador único. O \textit{ID do Google Drive} é o identificador único que é gerado automaticamente quando o arquivo com as informações da imagem da face são salvos.
Para o armazenamento dos arquivos no Google Drive, o seu acesso é feito a partir da biblioteca \textit{Pydrive}, onde cada arquivo tem as seguintes infromações armazenadas:
\begin{itemize}
\item Valor de $\Phi$ da face ou valor de $\Psi$ da face ou valor das eigenfaces;
\end{itemize}
Os valores são armazenados em um arquivo \textit{JSON}, sendo o JSON uma notação de objetos JavaScript, onde é um formato de texto independente de linguagem de programação, pode ser interpretado pelas mais diversas linguagens. Para o armazenamento dos valores poderiam ser utilizadas outras formas de salvar o arquivo, contudo foi escolhido o arquivo JSON para a facilitação ao acesso das informações, já que as mesmas são armazenadas em formato de lista, sendo mais fácil de fazer a transformação para vetores da biblioteca \textit{Numpy}.

\section{Atestado de Presença}
O processo de atestado de presença de um aluno ocorre sempre que sua face já foi tratada pelo sistema, contudo existem duas possibilidades dentro do sistema, que são tratadas de formas diferentes, sendo elas:

\begin{itemize}
\item Inserção da presença no sistema
\end{itemize}
Após a aquisição da imagem, segmentação da face do aluno, cálculo de seus pesos $\Omega$ e classificação de sua face, a presença é atribuida ao aluno se caso ele seja pertencente ao banco de faces do sistema. 

\begin{itemize}[resume]
\item Análise de presença pelo administrador
\end{itemize}
A análise da presença ocorre caso o aluno não seja reconhecido pelo sistema, sendo assim se faz necessário que o aluno coloque manualmente o seu nome no sistema, com isso sua presença pode ser computada e um log é gerado para o administrador do sistema, com as informações inseridas pelo aluno, juntamente com a foto adquirida no momente em que a presença foi realizada pelo sistema.

Para fins de registro e documentação, as presenças realizadas pelo sistema podem ser acessadas e baixadas pelo administrador do sistema.


\section{Integração do Sistema}
Na sua etapa final, todas as partes desenvolvidas serão integradas em uma versão final, já que ao longo do desenvolvimento do sistema as partes serão testadas para não haver algum tipo de problema na integração dos mesmos. O funcionamento do sistema pode ser visto na fig. \ref{sistema}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8\textwidth]{figuras/sistema.png}
	\caption{Diagrama do sistema.}
	\label{sistema}
\end{figure}


%Com isso o sistema final possui duas formas de acesso, a de administrador e a de usuário, possui funções de cadastro de face, de dados e de presença, 

\chapter{Resultados e Experimentos}

Nesta seção serão discutidos os resultados obtidos a partir da aplicação construida e das eigenfaces obtidas.

\section{Eigenfaces}

Durante o teste de reconhecimento a partir das eigenfaces calculadas previamente, foram utilizadas 50 imagens (100 imagens totais, devido ao espelhamento de cada imagem) de faces diferentes que são pertencentes as da base de treinamento, porém possuem um distúrbio em cada imagem (o distúrbio da imagem são as modificações do rosto de cada pessoa, pois estão sorrindo). Para a classificação a fórmula \ref{error} foi utilizada, obtendo um acerto de 80\% das faces testadas, utilizando somente o erro mínimo para a seleção da face. Assim com o valor de erro de cada face obtido, foi necessário procurar qual a face que havia obtido o menor erro, os resultdos podem ser observados na Figura \ref{erro_face}

\begin{figure}[htb]
        \centering
        \subfloat[]{
            \begin{minipage}{0.45\linewidth}
              \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{figuras/erro_face_win.png}             
            \end{minipage}} 
        \subfloat[]{
            \begin{minipage}{0.45\linewidth}
             \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{Figuras/erro_face_lose.png}
            \end{minipage}}     
           \caption{Face de teste, Face reconhecida do banco e Face reconhecida do sistema: (a) Face que foi reconhecida, (b) Face não foi reconhecida}
           \label{erro_face} 
    \end{figure}

A primeira face da Figura \ref{erro_face}(a) é a face que foi utilizada como teste de reconhecimento, a segunda e terceira face são as faces que foram reconhecidas como as que possuiam o menor valor de erro, sendo a segunda obtida do banco de imagens armazenadas no banco de dados e a terceira a armazenada na execução do algoritmo. Porém a Figura \ref{erro_face}(b) mostra uma face de teste que foi reconhecida erroneamente com outra face da base de treinamento.

Dentro dos testes de reconhecimento realizados com o algoritmo, foram utilizados diversas quantidades de eigenfaces, pois segundo \citep{turk2}, utilizar somente as \textit{K} melhores eigenfaces esta diretamente relacionado a eficiência computacional, já que o tamanho do banco de imagens que é utilizada pelo sistema pode aumentar conforme a necessidade de cada sistema. Neste trabalho foram utilizadas 196 imagens para o total da base de treinamento. A Figura \ref{k_win} exemplifica a relação da utilização de \textit{K} para a quantidade de acertos e a Figura \ref{k_lose} a relação de \textit{K} para erros. A quantidade de acertos e erros foram computadas observando manualmente cada imagem do teste com o as imagens da base de treinamento, um exemplo desta validação esta na Figura \ref{erro_face}, onde a imagem era comparada manualmente caso obtivesse um um resultado satisfatório, foi computado como um acerto e caso não como um erro.  

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.85\textwidth]{figuras/k_win.png}
	\caption{Gráfico K x Acertos.}
	\label{k_win}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.85\textwidth]{figuras/k_lose.png}
	\caption{Gráfico K x Erros.}
	\label{k_lose}
\end{figure}

Com os resultados de \textit{K}, observou-se que um dos melhores valores para a utilização para o algoritmo foi o de $K = 70$, sendo assim foram utilizadas as melhores 70 eigenfaces obtidas previamente no processo de reconhecimento.
Os valores dos omegas de cada imagem de teste projetada no espaço de faces, possui um valor de desvio padrão que aparece estar próximo das faces que possuem características semelheantes. O efeito do desvio padrão pode ser notado na Figura \ref{s_omegap}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.85\textwidth]{figuras/s_omegap.png}
	\caption{Desvio Padrão dos Omegas projetados no espaço de faces.}
	\label{s_omegap}
\end{figure}

Este efeito pode ser notado também no desvio padrão das imagens utilizadas no conjunto de treinamento, onde cada face que possui  características semelheantes, acabam tendo um valor mais próximo do outro e fazendo um agrupamento no gráfico da Figura \ref{s_omega}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.85\textwidth]{figuras/s_omega.png}
	\caption{Desvio Padrão dos Omegas no espaço de faces.}
	\label{s_omega}
\end{figure}

Contudo durante os testes para obter o melhor valor de \textit{K}, notou-se que algumas faces estavam sendo comparadas e obtido o menor valor mas o rosto correto não estava dentro do menor valor da fórmula \ref{error}, sendo assim foi necessário utilizar outro valor para ser uma segunda forma de comparação e validação. Com isso a fórmula \ref{erro_phi} foi utilizada como forma de validação, onde o menor valor foi utilizado.

\begin{equation}
\label{erro_phi}
	e_\Phi = min \| \widehat{\Phi} - \Phi_i \|
\end{equation}

Com a utilização da fórmula \ref{erro_phi}, notou-se que houve um aumento de 10\% de acertos em comparação com o teste anterior, este teste foi feito olhando cada imagem do teste comparada com a imagem do treinamento, validando manualmente, mas se fez necessário utilizar uma forma de fazer este reconhecimento automaticamente, utilizando os valores de \textit{Erro mínimo de $\Omega$} e o \textit{Erro mínimo de $\Phi$}, sendo assim a Figura \ref{erro_phi30_def} possui uma comparação das faces reconhecidas manualmente com as faces reconhecidas sem nenhum tipo de verificação.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi30_def.png}
	\caption{Faces reconhecidas do treinamento utilizando Erro $\Phi = 30$.}
	\label{erro_phi30_def}
\end{figure}

Cada valor de \textit{Threshold de Phi} foi testado reconhecendo cada face novamente, para poder obter um resultado mais próximo do valor que foi reconhecido manualmente. Pode-se notar que em cada figura, existe uma diferença de erro entra a o reconhecimento manual e o sem supervisão, pode-se dizer que este efeito de falso e verdadeiro negativo.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi31_def.png}
	\caption{Faces reconhecidas do treinamento utilizando Erro $\Phi = 31$.}
	\label{erro_phi31_def}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi32_def.png}
	\caption{Faces reconhecidas do treinamento utilizando Erro $\Phi = 32$.}
	\label{erro_phi32_def}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi33_def.png}
	\caption{Faces reconhecidas do treinamento utilizando Erro $\Phi = 33$.}
	\label{erro_phi33_def}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi34_def.png}
	\caption{Faces reconhecidas do treinamento utilizando Erro $\Phi = 34$.}
	\label{erro_phi34_def}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi35_def.png}
	\caption{Faces reconhecidas do treinamento utilizando Erro $\Phi = 35$.}
	\label{erro_phi35_def}
\end{figure}

Com os gráficos das Figuras \ref{erro_phi30_def} a \ref{erro_phi35_def} pode-se notar que as imagens possuem um valor de \textit{Erro Phi} abaixo de 30. Para poder obter uma confirmação neste valor, o teste que foi feito para garantir este valor é tentar reconhecer faces que estão fora das faces de treinamento. Os gráficos dos teste estão referenciados nas Figuras \ref{erro_phi30_des} a \ref{erro_phi35_des}. Analisando cada gráfico pode-se notar que faces que são desconhecidas do sistema possuem um valor de \textit{Erro Phi} acima de 30. Com isso é possível utilizar um valor entre 30 e 35 como \textit{Threshold}.

A decisão foi feita com base em minimizar o efito de falsos e verdadeiros negativos, já que com o aumento do valor, existe mais possibilidade de uma face ser atribuida erroneamente com outra.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi30_des.png}
	\caption{Faces reconhecidas de fora do treinamento utilizando Erro $\Phi = 30$.}
	\label{erro_phi30_des}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi31_des.png}
	\caption{Faces reconhecidas de fora do treinamento utilizando Erro $\Phi = 31$.}
	\label{erro_phi31_des}
\end{figure}

O valor utilizado de trinta obtem também um erro atrelado as faces desconhecidas do sistema, onde erroneamente acaba considerando algumas faces como pertecentes ao conjunto de treinamento. A quantidade de erros diminui juntamente com a diminuição do valor de menor erro de $\Phi$, assim isto mostra que a fórmula \ref{erro_phi} reproduz a diferença de cada face uma das outras, tendo a diferença de PCA de cada face. 

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi32_des.png}
	\caption{Faces reconhecidas de fora do treinamento utilizando Erro $\Phi = 32$.}
	\label{erro_phi32_des}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi33_des.png}
	\caption{Faces reconhecidas de fora do treinamento utilizando Erro $\Phi = 33$.}
	\label{erro_phi33_des}
\end{figure}

Pode-se elencar que algumas faces acabam sendo consideradas como pertencentes ao conjunto de treinamento devido a igualdade de certas características humanas, sendo este um fator que deve ser levado em consideração para fazer uma análise de grupos de faces.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi34_des.png}
	\caption{Faces reconhecidas de fora do treinamento utilizando Erro $\Phi = 34$.}
	\label{erro_phi34_des}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/erro_phi35_des.png}
	\caption{Faces reconhecidas de fora do treinamento utilizando Erro $\Phi = 35$.}
	\label{erro_phi35_des}
\end{figure}

Para se fazer uma análise dos valores de falsos e positivos negativos que podem ocorrer com o aumento do valor de \textit{Erro Phi}, esses valor podem ser notados na tabela \ref{tab:tabela1}, onde \textbf{FN} é a quantidade de valores de \textit{"Falsos Negativos"}, \textbf{FP} é a quantidade de valores de \textit{"Falsos Positivos"}, \textbf{Iguais} é a quantidade de valores que são iguais ao valores comparados com o valor de acertos supervisionados, \textbf{Acertos} é a quantidade de valores que o sistema acertou de faces sem supervisão e \textbf{Erros} é a quantidade de valores que o sistema errou de faces sem a supervisão do sistema.

\begin{table}[h!]
	\begin{center}
		\caption{Falsos positivos e negativos}
		\label{tab:tabela1}
		\begin{tabular}{c|c|c|c|c}
		\textbf{FN} & \textbf{FP} & \textbf{Iguais} & \textbf{Acertos} & \textbf{Erros}\\
		\hline		
		\multicolumn{5}{c}{$e_\Phi$ = 30}\\
		\hline
		14 & 2 & 84 & 76 & 24\\
		\hline
		\multicolumn{5}{c}{$e_\Phi$ = 31}\\
		\hline
		12 & 2 & 86 & 78 & 22\\
		\hline
		\multicolumn{5}{c}{$e_\Phi$ = 32}\\
		\hline
		10 & 2 & 88 & 80 & 20\\
		\hline
		\multicolumn{5}{c}{$e_\Phi$ = 33}\\
		\hline
		8 & 2 & 90 & 82 & 18\\
		\hline
		\multicolumn{5}{c}{$e_\Phi$ = 34}\\
		\hline
		8 & 4 & 88 & 84 & 16\\		
		\hline
		\multicolumn{5}{c}{$e_\Phi$ = 35}\\
		\hline
		4 & 4 & 92 & 88 & 12\\
		\end{tabular}
	\end{center}
\end{table}

Pode-se notar que conforme o valor de $e_\Phi$ vai aumentando, a quantidade de falsos negativos tende a diminuir, sendo assim pode-se notar que escolher somente um valor de \textit{Threshold} é uma limitação, pode utilizar ao invés de somente um valor ser uma faixa, sendo assim a faixa vai de 30 a 35. Com todos os valores de \textit{Threshold}, face $\Psi$ e eigenfaces, pode-se utilizar isto para a verificação no sistema.

\section{Armazenamento}
Dentro do desenvolvimento do trabalho proposto, foi necessário criar um meio de armazenar e recuperar as imagens e valores utilizados pelo sistema. O acesso das imagens feito localmente não possui um atraso para a obtenção de cada imagem, contudo caso exista algum tipo de perda do sistema por meios físicos, as imagens serão perdidas e será necessário reconfigurar o sistema. Com isso em mente o armazenamento externo foi pensado, sendo esta uma forma mais prática de salvar as informações do sistema, contudo existe o atraso para a recuperação das informações que foram salvas externamente.

O processo de armazenamento em ambos os bancos ocorre em três etapas, sendo elas: Gerar as informações da face (valores de $\Phi$ e $\Omega$ de cada face individualmente), salvar essas informações no Google Drive e devolver o ID que foi salvo e salvar no Mongo o ID do Gogle Drive juntamente com o nome de cada pessoa. Um exemplo deste processo pode ser notado na Figura \ref{fluxo_banco}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/fluxo_arm.jpg}
	\caption{Armazenamento das imagens a partir dos Bancos de Dados.}
	\label{fluxo_banco}
\end{figure}


Para a análise de um nova face, é necessário buscar os valores de cada face no banco de imagens, a forma de busca é feita a partir dos valors de $\Omega$, que foram armazenados previamente, e devolvido o valor de $\Phi$ da face reconhecida (deve-se após receber o valor de $\Phi$ somar o valor de $\Psi$ que também está armazenado no banco de imagens). O método de utilização de ambos os bancos pode ser notado na Figura \ref{recupera_img}
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\textwidth]{figuras/recupera_img.jpg}
	\caption{Recuperação das imagens a partir dos Bancos de Dados.}
	\label{recupera_img}
\end{figure}

Para poder demonstrar que existe um atraso para a recuperação das imagens armazenadas o seguinte experimento foi feito: as imagens são armazenadas no Google Drive e o identificador único atrelado ao arquivo é gerado, este identificador é salvo posteriormente no banco de dados do MongoDB. Os arquivos foram divididos em três classes sendo elas, a face média $\Psi$ (contém somente um arquivo), as eigenfaces (contém setenta arquivos diferentes) e as faces $\Phi$ (contém cento e noventa e seis arquivos diferentes). O sistema recupera cada imagem a partir de seu identificador, com isso a tabela \ref{tab:time} foi gerada.

\begin{table}[h!]
	\begin{center}
		\caption{Tempo de recuperação das imagens}
		\label{tab:time}
		\begin{tabular}{ |c|c|c|c| }	
		\hline		
		 & \textbf{$\Psi$} & \textbf{Eigenfaces} & \textbf{$\Phi$}\\
		\hline
		Qnt Arquivos & 1 & 70 & 196\\		
		\hline		
		Tempo Gasto & 2,2s & 157s & 475s\\
		\hline
		\end{tabular}
	\end{center}
\end{table}

Os tempos de aquisições dos arquivos estão diretamente atrelado ao acesso ao Google Drive, devido que o tempo para a obtenção de todos os identificadores que estão armazenados no MongoDB acaba não levando mais do que um segundo. Com um total de 635 segundos para obter todos os arquivos necessários para o funcionamento do sistema, estes arquivos devem ser carregados na inicialização do sistema e ser utilizado localmente, devido a esta quantidade de tempo necessária para fazer a requisição dos arquivos, pois para cada face que irá ser reconhecida é necessário todos os arquivos armazenados, sendo assim o tempo total mais o tempo para o reconhecimento seria o tempo total que o usuário deve esperar pra poder ser reconhecido.

\chapter{Conclusão} 

\chapter{Trabalhos Futuros}

Como trabalhos futuros, existe a possibilidade de utilizar Redes Neurais para poder modificar cada valor de $\Omega$, podendo assim reconhecer uma face diretamente pelo seu peso atrelado, sem necessidade de utilizar somento o valor de um \textit{Threshold} mínimo e recalcular para cada pessoa o seu peso da face.

\bibliography{tcc_template}

%\appendix

%\begin{center}
%\chapter{Detalhes sobre um ítem %específico do trabalho}
%\end{center}	


%\begin{verbatim}	
%apendice
%\end{verbatim}



\end{document}
