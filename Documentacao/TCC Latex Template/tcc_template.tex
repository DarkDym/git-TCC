\documentclass[tc,openright]{ii}

\usepackage[T1]{fontenc}        % pacote para conj. de caracteres correto
\usepackage[latin1]{inputenc}   % pacote para acentua\c c\~ ao
\usepackage{graphicx}           % pacote para importar figuras
\usepackage{times}              % pacote para usar fonte Adobe Times
\usepackage{multirow}
%\usepackage{listings}
%\usepackage{scalefnt}
\usepackage{amsmath}
\usepackage[brazilian]{babel}
\usepackage{amsmath}
\usepackage{subfig}
\usepackage{threeparttable}
\usepackage{float}
\usepackage{color}
\restylefloat{table}

\bibliographystyle{abnt}

\hyphenation{en-si-na-men-tos a-gra-de-ci-men-to de-se-nha-dos}


\title{RECONHECIMENTO FACIAL PARA CLASSIFICAÇÃO E REGISTRO DE PRESENÇA EM SALA DE AULA}

\author{Deus}{Alleff Dymytry Pereira de}

\advisor[Profa.~Dra.]{Guimarães}{Letícia Vieira}


% a data deve ser a da defesa; se nao especificada, são gerados
% mes e ano correntes
\date{Dezembro}{2020}

\course{Engenharia de Computação}

\location{Guaíba}{RS}

\keyword{Eigenfaces}
\keyword{Reconhecimento Facial}
\keyword{Haar Like Features}
% inicio do documento
\begin{document}


\maketitle



\begin{folhadeaprovacao}
Monografia sob o título \textit{"Reconhecimento Facial para Classificação e Registro de Presença em Sala de Aula"}, defendida por Alleff Dymytry Pereira de Deus e aprovada em 3 de Julho de 2020, em Guaíba, estado do Rio Grande do Sul, pela banca examinadora constituída pelos professores:
    \assinatura{Profa. Dra. Adriane Parraga \\ Orientadora}
    \assinatura{Prof. Dr. João Leonardo Fragoso}
        \assinatura{Profa. Dra. Letícia Vieira Guimarães}
    \assinatura{Prof. Dr. Roberto Ribeiro Baldino}

\end{folhadeaprovacao}


% dedicatoria
\clearpage
\begin{flushright}
\mbox{}\vfill
{\sffamily\itshape
"Você deve entender que há mais de um caminho para o topo da montanha.''\\}
--- \textsc{Miyamoto Musashi}
\end{flushright}

% agradecimentos
\chapter*{Agradecimentos}
Aos meus ....
\vspace{0.5cm}


\vspace{0.5cm}


À minha ...
\vspace{0.5cm}


Aos meus...
\vspace{0.5cm}


À Universidade, professores e funcionários que propiciaram um excelente ambiente de aprendizagem.

% sumario
\tableofcontents

% lista de abreviaturas e siglas
\begin{listofabbrv}{SPMD}
        \item[PCA] Principal Component Analisys
        \item[PDS] Processamento Digital de Sinais
	\item[RNA] Rede Neural Artificial
	\item[SLIT] Sistemas Lineares e Invariantes no Tempo
	\item[FPA] Filtro Passa-Alta
	\item[FPB] Filtro Passa-Baixa
	\item[FIR] \textit{Finite Impulse Response} (Resposta ao Impulso Finita)
	\item[IIR] \textit{Infinite Impulse Response} (Resposta ao Impulso Infinita)
	\item[ADC] \textit{Analog-to-digital converter} (Conversor Analógico-Digital)
	\item[TF] Transformada de Fourier
	\item[TDF] Transformada Discreta de Fourier
	\item[STFT] \textit{Short Time Fourier Transform} (Transformada de Fourier de Tempo Reduzido)
\end{listofabbrv}

% lista de figuras
\listoffigures

% lista de tabelas
\listoftables

% resumo
\begin{abstract}

Este trabalho tem por objetivo o desenvolvimento de um sistema que detecta faces para o auxílio no registro de alunos presentes no ambiente acadêmico. Para a localização facial será utilizado o método de classificação Haar Like Features e para a classificação das faces encontradas será utilizado o método Eigen Faces. Para  a facilidade de utilização do usuário final, os métodos irão ser integrados em um sistema que possibilita a inclusão dos dados diretamente no banco de dados, possibilitando a consulta dos mesmo com mais agilidade. 

 \end{abstract}

% abstract
\begin{englishabstract}
{Facial Recognition for Classification and Register on Presence in Classroom}
{Eigenfaces,Facial Recognition,Haar Like Features}
(COLOCAR EM INGLES DEPOIS)Este trabalho tem por objetivo o desenvolvimento de um sistema que detecta faces para o auxílio no registro de alunos presentes no ambiente acadêmico. Para a localização facial será utilizado o método de classificação Haar Like Features e para a classificação das faces encontradas será utilizado o método Eigen Faces. Para  a facilidade de utilização do usuário final, os métodos irão ser integrados em um sistema que possibilita a inclusão dos dados diretamente no banco de dados, possibilitando a consulta dos mesmo com mais agilidade.(COLOCAR EM INGLES DEPOIS) 
\end{englishabstract}

\chapter{Introdução}
Nos dias atuais pode-se notar que a biometria é algo amplamente utilizado e ajuda no cotidiano de todas as pessoas, já que pode-se fazer as mais diversas funções, sendo elas: pagamento de contas, liberação para áreas restritas, verificação em e-mails, para direção de um veículo, etc. A biometria tem por base a medição de características humanas de forma analógicas e transforma para o mundo digital, sendo uma delas a mais emergente o reconhecimento facial.

Segundo a ANSA, no carnaval de 2019, a polícia do Rio de Janeiro e do Salvador, conseguiram detectar e prender criminosos com a ajuda de câmeras equipadas com reconhecimento facial. Existe no mercado atual um crescimento de 20% até 30% por ano na área.

O reconhecimento facial pode ser empregado nas mais diferentes áreas, sem ser a da segurança, com isso pode-se empregar o reconhecimento para verificar sentimentos, expressões, executar comandos configurados, check-in em eventos, entre outras aplicações.

Com esses avanços nas técnicas de reconhecimento facial, pode-se utilizar tais avanços para o reconhecimento de alunos em sala de aulas, já que os mesmos querem ter seus rostos reconhecidos para obter a presença em sala de aula, fazendo que o método tradicional de folha de chamada posso ser substituído e todo o sistema de presença seja diretamente integrado em um único sistema.

Desta forma, a construção de um sistema de reconhecimento facial integrado com um controle de presença se faz necessário para sanar o problema de ainda hoje, em um tempo de integração e avanço tecnológico, utilizar chamadas impressas para marcar se o aluno estava ou não em aula ou em um determinado evento.
   

\chapter{Fundamentos Teóricos}
Neste capítulo serão abordados os conhecimentos necessários para a contextualização do presente trabalho, bem como seus métodos de desenvolvimento e funcionalidades específicas.
O processo de funcionamento do presente trabalho segue a ordem indicada na figura \ref{aquisicao}

\begin{figure}[htb]
   \centering
   \includegraphics[width=0.8\textwidth]{figuras/metodologia.png}
   \caption{Esquemático do método de classificação.}
   \label{aquisicao}
\end{figure}

\begin{itemize}
\item AQUISIÇÃO: O processo de aquisição se refere ao momento em que o usuário tem sua face adquirida por um dispositivo de captura (câmera, filmadora, webcam, etc.);

\item LOCALIZAÇÃO: O processo de localização tem por funcionamento encontrar uma face na imagem adquirida no processo anterior;

\item SEGMENTAÇÃO: O processo de segmentação por sua vez retira para o sistema somente a face localizada no processo anterior, facilitando a próxima etapa do sistema;

\item CLASSIFICAÇÃO: O processo de classificação consiste em utilizar a face para o reconhecimento de qual usuário está no sistema;

\item INSERÇÃO: O processo de inserção finaliza o sistema, inserindo qual usuário que foi reconhecido pelos processos anteriores.
\end{itemize}
%Na seção \ref{r1} é feita uma breve abordagem sobre...

\section{EIGENFACES}\label{r1}
No contexto de análise de imagens, existe um problema em qualquer tipo de classificação, sendo ele o tamanho das dimensões da imagem, onde um problema simples pode se tornar complexo, já que uma imagem em escala de cinza de 300 pixels por 300 pixels irá possuir um total de 90000 valores diferentes $(m = i \times j)$.
Sendo assim é necessário retirar das imagens somente o que interessa, para isso é utilizado o método de análise de componentes principais (PCA), onde serão extraídas das imagens as partes que possuem as maiores relevâncias dentro do espaço de distribuição de dados.

O PCA é feito pela decomposição em autovetores de uma matriz de covariância, sendo o autovetor o maior autovalor associado correspondente do da componente principal de cada conjunto.
 
\subsection{Reconhecimento Utilizando Eigenfaces}

Pode-se utilizar eigenfaces para reconhecimento facial, alguns passos devem ser feitos antes do reconhecimento concreto, levando em consideração que as imagens utilizadas estão centralizadas e possuem os mesmos tamanhos. Sendo assim pode-se dividir o processo em duas etapas, a primiera de treinamento e o segundo de reconhecimento. Para a etapa de treinamento os seguintes passos devem ser feitos:

\begin{itemize}

\item Adquirir uma coletânea de imagens para ser o conjunto de treinamento;
\item Deixar as imagens no tamanho desejado, cortando somente a face como objeto de insteresse;
\item Transformar o vetor de imagens I ($I = N \times N$) em um vetor gamma $\Gamma$ ($\Gamma = N^{2} \times 1$);
\item Calcular a face média $\Psi$ do vetor $\Gamma$;
\item Calcular o PCA ($\Phi$) de cada face do conjunto $\Gamma$;
\item Obter a matriz de covariância $C$;

%Arrumar depois
\item Obter os Autovalores(Eigenvalues) e Autovetores(Eigenvectors) da matriz de Covariância $C$;
\item Selecionar os melhores M autovetores; 
\item Manter somente os K melhores autovetores(K com maiores autovalores)%Treshold

\end{itemize}

A segunda etapa sendo a de reconhecimento, se utiliza uma face que esta fora do conjunto de treinamento para poder fazer a validação, além de que deve estar com o mesmo tamanho das imagens do conjunto de treino, seguindo os seguintes passos:

\begin{itemize}

\item Normalizar a imagem $\Gamma$ : $\Phi = \Gamma - \Psi$


\end{itemize}



\begin{itemize}

\item Calcular um conjunto de pesos baseados na imagem de entrada e as M Eigenfaces projetando a imagem de entrada em cada uma das Eigenfaces;
\item Determinar se a imagem de entrada é uma face, calculando se a imagem está suficientemente próxima do espaço facial;
\item Se for uma face, classificar os padrões de peso para saber se é uma pessoa conhecida ou desconhecida;

\end{itemize}


\section{SISTEMAS EMBARCADOS}\label{r2}
Atualmente a tecnologia está cada vez mais popular e acessível, sendo assim possui-se diversos tipos diferentes de tecnologias para os mais diversos fins, sendo assim um conceito para que essas tecnologias possam ser classificadas e separadas para os seus específicos fins, pode-se utilizar o conceito de sistemas embarcados. Os sistemas embarcados são tecnologias que são construídas para devidos fins específicos com hardware específico que acaba não podendo ser reutilizado em outras aplicações que não possuam o mesmo hardware utilizado em seu desenvolvimento original.

Os sistemas embarcados podem normalmente desempenhar processos simples, que não geram nenhum tipo de risco para os usuários (exemplo de calculadoras, controles de videogames, telefones, etc.), contudo também podem ser utilizados para tarefas mais complexas que apresentam certos riscos se não forem projetados com um maior rigor (exemplo controle em aviões, controles industriais, monitoramento de saúde, etc.).

Neste âmbito um sistema desenvolvido para um hardware específico pode ser considerado um sistema embarcado, neste tipo de aplicação um hardware muito utilizado atualmente são as RaspberryPi, que são microprocessadores que rodam sistemas operacionais de diversos tipos.


\begin{table}[ht]
\begin{center}
    \begin{tabular}{ | l | l | p{6.5cm} |}
    \hline
    Tipo & Intensidade & Descrição \\ \hline

    Vesicular & Suave  & Formado pela passagem do ar pelo parênquima pulmonar. \\ \hline

    Bronquial & Alta  & Som traqueal audível na zona de projeção de brônquios de maior calibre. \\ \hline

    Broncovesicular  & Intermediária  & Somam-se as características do som bronquial com o som vesicular. \\ \hline

    Traqueal & Muito alta & Som produzido na traqueia pela passagem do ar. \\  \hline
    \end{tabular}
    \caption{Tipos de sons normais.} % title of Table
\label{tsonsnormais}

\end{center}
\end{table}


\begin{equation}
N = 300
\end{equation}
\begin{equation}
N^2 = 90000
\end{equation}
\begin{equation}
M = 196
\end{equation}
\begin{equation}
K = 50
\end{equation}
\begin{equation}
I \rightarrow N \times N
\end{equation}
\begin{equation}
\Gamma \rightarrow N^2 \times 1
\end{equation}
\begin{equation}
\Psi \rightarrow N^2 \times 1
\end{equation}
\begin{equation}
\Phi_i \rightarrow N^2 \times 1
\end{equation}
\begin{equation}
C \rightarrow N^2 \times N^2
\end{equation}
\begin{equation}
A \rightarrow M \times N^2
\end{equation}
\begin{equation}
C_{mod} \rightarrow M \times M
\end{equation}
\begin{equation}
u \rightarrow M \times N^2
\end{equation}
\begin{equation}
w_i \rightarrow 1 \times 1
\end{equation}
\begin{equation}
\Omega_i \rightarrow K \times 1
\end{equation}
\begin{equation}
\Omega_i = \lceil w_1 \rceil \\ \vert w_2 \vert
\end{equation}


\begin{equation}
{y[n]} = x[n] * h[n] = \sum \limits _{k=-\infty}^{\infty} {x[k].h[n-k]} \label{conv}
\end{equation}


\begin{figure}[htb]
        \centering
        \subfloat[]{
            \begin{minipage}{0.338\linewidth}
              \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{Figuras/8.png}             
            \end{minipage}} 
        \subfloat[]{
            \begin{minipage}{0.324\linewidth}
             \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{Figuras/8.png}
            \end{minipage}}
        \subfloat[]{
            \begin{minipage}{0.338\linewidth}
              \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{Figuras/8.png}
            \end{minipage}}
             
           \caption{Espectros dos sinais: (a) sinal $X(f)$, (b) trem de impulsos, (c) sinal $X(f)$ multiplicado pelo trem de impulsos.}
           \label{samp2} 
    \end{figure}

\chapter{Materiais e métodos}

Neste capítulo serão abordados os materiais utilizados para a construção e desenvolvimento do presente trabalho, bem como os métodos discutidos anteriormente. 

\section{MATERIAIS}\label{mm1}

A aplicação será desenvolvida utilizando a linguagem de programação Python, sendo ela a linguagem escolhida devido ao seu maior acervo bibliográfico referente as funções necessárias para a o desenvolvimento de presente trabalho.

Para o tratamento e requisições das imagens, será utilizado a biblioteca OpenCV, devido ao seu alto grau de conceituação na literatura atual além de ser de código aberto e com uma ampla disponibilidade de documentação.

Para o armazenamento das informações necessária para gerar as presenças dentro da aplicação, será utilizado o banco de dados não relacional MongoDB, devido a não necessidade de relação entre as informações inseridas nas tabelas do banco criado, assim como a inserção das informações das imagens. Além de possuir conexão com a linguagem escolhida para a criação da aplicação.
Para o desenvolvimento da interface gráfica, será utilizado o framework de desenvolvimento gráfico PyQt, gerando uma interface ?amigável? para todos os tipos de usuários, além de disponibilizar mais facilmente as opções de gerência do banco de dados utilizado.

O banco de imagens para o treinamento e o teste dos métodos previamente descritos, são o banco FEI face database, YALE face database e um banco de dados criado manualmente. O banco FEI é um banco de imagens faciais brasileiro que possui 14 imagens de 200 indivíduos, totalizando 2800 imagens. O banco YALE possui 165 imagens de 15 indivíduos, totalizando 2475 imagens.

Os testes serão realizados em uma Raspberry Pi 3, que possui um processador ARMv8 CORTEX A53 QUADCORE com velocidade de operação de 1.2GHz e 1GB de memória RAM. Utilizando o sistema operacional Linux para executar a aplicação desenvolvida.

\section{PYTHON}

Python é uma linguagem de programação considerada de alto nível, tendo o seu funcionamento interpretado, onde o programa é executado por um interpretador e após pelo sistema operacional ou processador. A linguagem também é orientada a objetos e funcional. Foi criada em 1991. Possui uma grande comunidade, já que a linguagem possui um modelo de desenvolvimento comunitário, onde várias pessoas podem ajudar a desenvolver novas bibliotecas para que toda a comunidade posso utilizar.

\section{OPENCV}

O OpenCV é uma biblioteca de visão computacional e aprendizagem de máquina com código livre, possuindo mais 2500 algoritmos otimizados para uso de todos. Os algoritmos vão desde detectar objetos até extração de modelos 3D. A biblioteca pode ser utilizada nas linguagens de programação Python, C++, Java e MatLab, tendo seus códigos escritos nativamente em C++.

\section{MONGODB}

O MongoDB é um banco de dados não relacional que utiliza documentos para armazenar informações, utilizando informações na linguagem JSON. Podendo se conectar com as mais diversas linguagens de programação (como por exemplo: Java, Python, Ruby, C++, etc). Pode ser utilizado com repositórios locais ou até mesmo com repositórios armazenados em nuvem de forma gratuita (conforme utilização do armazenamento e acesso repetidos dos dados). Dentro de algumas de suas vantegens, pode-se elencar a relação de não ser necessário as condições relacionais para começar a armazenar dados, obtendo melhor performace em relação as suas consultas, já que tudo esta dentro de um único documento. Contudo isso acaba sendo uma desvantagem também, pois caso seja necessário a modificação de algum atributo para todos as entradas, cada valor deve ser tratado um a um.

\section{EIGENFACES}

Eigenface é um classificador de faces utilizado em visão computacional, utiliza autovetores para poder fazer a aproximação do valor de rosto médio com o rosto em questão. A criação do conceito de eigenfaces foi criada em 1987 por Sirovich e Kirby, tendo como primeira intenção de uma aproximação de uma representação de imagens em dimensões menores. As eigenfaces podem ser geradas a partir de um processo matemático chamado de Análise de Componente Principal (PCA) em um banco de imagens de faces consideravelmente grande. Pode-se utilizar as Eigenfaces para a classificação e reconhecimento facial, como feito por \citep{turk2}, onde foram utilizadas para reconhecer faces de pessoas da equipe de pesquisa. Foram elencados certos problemas da utilização das mesmas, onde a iluminação, orientação e obstrução das imagens podem afetar diretamente no reconhecimento de cada face.

\section{METODOLOGIA}

Nesta seção serão apresentadas as etapas de desenvolvimento do presente trabalho seguindo o caminho da fig. \ref{diagrama}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{figuras/diagrama.png}
	\caption{Diagrama das etapas de desenvolvimento.}
	\label{diagrama}
\end{figure}

O desenvolvimento do presente trabalho possuí uma construção paralela das funções para que se possa ir integrando cada parte do sistema, afim de chegar no final do desenvolvimento com todas as funções funcionando integralmente, sendo assim o início do desenvolvimento segue a etapa de aquisição das imagens, tendo em paralelo o desenvolvimento de uma interface que seja de simples acesso e o mais claro possível para o usuário final. As imagens serão adquiridas utilizando um algoritmo, contendo a biblioteca OpenCV, sendo executado na Raspberry Pi juntamente com uma câmera (podendo ser um webcam ou uma Raspicam).
 
Após a obtenção das imagens é necessário fazer a segmentação do rosto encontrado, considerando somente a face (do queixo até início da cabeça), em paralelo será construído e integrado o banco de dados com a interface, já que será necessário analisar como os dados das imagens adquiridas serão armazenadas no banco de dados (para que não seja necessário armazenar nenhum tipo de informação na RaspberryPi, devido ao seu espaço limitado de armazenamento). 

Assim que a face estiver segmentada, poderá ser aplicado o classificador Eigenfaces (a segmentação se faz necessária para que o fundo da imagem e qualquer outro objeto não influencie na classificação do indivíduo) para o reconhecimento do indivíduo em questão, como dito anteriormente, em paralelo será testado funções de frequência/presença no sistema, para que o objetivo final do sistema, que seria de por meio do reconhecimento facial a presença do indivíduo, da qual quer ser reconhecido, receberá presença dentro do sistema.
 
Na sua etapa final, todas as partes desenvolvidas serão integradas em uma versão final, já que ao longo do desenvolvimento do sistema as partes serão testadas para não ter nenhum tipo de problema na integração dos mesmos. O funcionamento do sistema pode ser visto na fig. \ref{sistema}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8\textwidth]{figuras/sistema.png}
	\caption{Diagrama do sistema.}
	\label{sistema}
\end{figure}

\chapter{Resultados e discussões}

Nesta seção serão discutidos os resultados obtidos a partir da aplicação construida e das eigenfaces obtidas.

\section{Obtenção das Eigenfaces}

A primeira etapa para o processo de obtenção das eigenfaces é obter um conjunto de imagens, estas imagens serão o grupo de treinamento um exemplo de algumas das imagens utilizadas nesta etapa pode ser notada na Figura \ref{faces}, as imagens foram utilizadas para o treinamento, tiveram a face cortada, pois somente é necessário utilizar uma parte menor do rosto para o reconhecimento, sendo assim após o corte e tranformação em um único canal de escala de cinza, para que a quantidade de cálculos diminuisse (Imagem sem modificar $I: (N \times N \times 3)$, imagem modificada $I: (N \times N \times 1)$)  após deve-se transformar cada imagem $I : (N \times N)$ em um vetor gama $\Gamma : (N^2 \times 1)$, onde é necessário tranformar o vetor em uma dimensão, para reduzir o tamanho dos cálculos as imagens foram redimensionadas no tamanho $N = 300 \times 300$ e possuem somente um canal em escala de cinza, um exemplo da imagem de treinamento pode ser vista na figura \ref{face}. As imagens podem ser normalizadas dividindo pelo valor máximo de 255 para facilitar os cálculos.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\textwidth]{figuras/faces.jpg}
	\caption{Faces sem tratamento pertencentes ao treino.}
	\label{faces}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.4\textwidth]{figuras/face1.jpg}
	\caption{Face tratada pertencente ao treino.}
	\label{face}
\end{figure}

Após este processo de achatamento da imagem, deve-se obter a face média do treinamento, sendo uma soma de todas as imagens presentes no treinamento e dividido pela quantidade de imagens, sendo obtida uma imagem psi na equação \ref{psi}.

\begin{equation}
\Psi = \dfrac{1}{M} \sum \limits _{i=1}^{M} \Gamma_i
\label{psi}
\end{equation}

A imagem gerada é um amalgama de todas as faces de treino, possuindo um pouco de cada característica mais exuberante de cada face, o resultado da junção das faces pode ser notada na figura \ref{psi_face}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.4\textwidth]{figuras/psi.jpg}
	\caption{Face média $\Psi$.}
	\label{psi_face}
\end{figure}

Cada face $\Gamma$ pode ser subtraida da face média $\Psi$ para assim formar um vetor de diferenças $\Phi$ presente na equação \ref{phi}, sendo estas as diferenças mais distintas de cada face, essa diferença pode ser notada nas figura \ref{phi_face}.

\begin{equation}
\Phi_i = \Gamma_i - \Psi
\label{phi}
\end{equation}
 
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.5\textwidth]{figuras/phi.jpg}
	\caption{Faces $\Phi$.}
	\label{phi_face}
\end{figure} 
 
Os autovetores e autovalores podem ser obtidas a partir da matriz de covarância do vetor $AA^T$ como pode ser visto na equação \ref{cov}, sendo este um vetor de $\Phi$, porém esta matriz possui um tamanho que pode ser um disperdicio computacional ($N^2 \times N^2$) então é necessário fazer o cálculo a partir da matriz transposta $A^T$ que é computacionalmente menor ($M \times M$). 

\begin{equation}
\label{cov}
	C = \dfrac{1}{M} \sum \limits _{i=1}^{M} \Phi_i\Phi_{i}^{T} = AA^T \hspace{1cm}(N^2 \times N^2)
\end{equation}

Sendo assim é necessário calcular os autovetores a partir de $A^T A$ e achar os autovetores de $AA^T$ a partir da relação da equação \ref{egvec}.

\begin{equation}
A^TAv_i = \mu_i v_i \Rightarrow
AA^TAv_i = \mu_i Av_i \Rightarrow
CAv_i = \mu_i Av_i \Rightarrow
onde\longrightarrow u_i = Av_i
\label{egvec}
\end{equation}

Sendo assim é possível encontrar os autovetores da matriz de covariância $AA^T$, sendo estes os maiores autovetores de dos autovetores de $A^T A$. Os autovetores podem ser referenciados como as eigenfaces que devem ser redimensionadas para que seja possível ser visualizadas em uma imagem. Alguns exemplos de eigenfaces obtidas podem ser vistas na figura \ref{eigenface}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.6\textwidth]{figuras/eigen.jpg}
	\caption{Eigenfaces.}
	\label{eigenface}
\end{figure}

Com as eigenfaces geradas é necessário calcular os pesos de cada eigenface nas diferentes faces do treinamento, os pesos calculados para cada face são obtidos utilizando as eigenfaces transpostas vezes a face $\Phi$ como na equação \ref{weigth}.

\begin{equation}
\label{weigth}
	w_j = u_{j}^{T}\Phi_i
\end{equation}

Os pesos $w_j$ são distintos para cada face, esses pesos mais a face média $\Psi$, resulta na face original $\Phi$, contudo essa reconstrução pode não ocorrer do jeito esperado, já que cada rosto possui uma forma própria mesmo que elas sejam alinhadas. Para representar as faces no "espaço de faces" é necessário reunir cada peso $w_j$ de cada face em um vetor $\Omega$ como na equação \ref{Omega}

\begin{equation}
\label{Omega}
	\Omega_i = \left[ \begin{array}{c}
				 w_{1}^{i} \\ w_{2}^{i} \\ w_{3}^{i} \\ \vdots \\ w_{K}^{i} 
			\end{array} \right], \hspace{2cm} i = 1,2,\cdots,M	 
\end{equation}

\subsection{Reconhecimento utilizando as Eigenfaces}

Para a fase de reconhecimento é necessário representar uma face nova, de fora do conjunto de treinamento, no "espaço de faces" normalizando ela com a face média $\Psi$ como na equação \ref{new_face} (a nova face já deve estar no formato de $\Gamma$ para ser representada).

\begin{equation}
\label{new_face}
	\widehat{\Phi} = \Gamma - \Psi
\end{equation}

Para a projeção das eigenfaces é necessário calcular o vetor de pesos $\Omega$ desta face $\Gamma$, utilizando as eigenfaces obtidas anteriormente, essa representação pode ser vista na equação \ref{project_face}

\begin{equation}
\label{project_face}
	 w_i = u_{i}^{T}\widehat{\Phi} \hspace{2cm}
	 \Omega = \left[ \begin{array}{c}
				 w_{1} \\ w_{2} \\ w_{3} \\ \vdots \\ w_{K} 
			\end{array} \right]
\end{equation}

Calculando o vetor $\Omega$ da nova face, é necessário achar o menor erro euclidiano entre os pesos da nova face menos os pesos de cada face do conjunto de treinamento. Este erro deve ser o menor possível e estar abaixo de um valor de \textit{threshold} para ser considerado a mesma face, a equação \ref{error} representa essa distância da face nova de cada face do conjunto de treino.

\begin{equation}
\label{error}
	e_r = min_l \hspace{1mm} \| \Omega - \Omega^l \| 
\end{equation}

 

O valor de \textit{Threshold} pode ser escolhido arbitrário ou perante um critério de cada aplicação, segundo \cite{marijeta}, não há uma formula para o cálculo de um valor de \textit{Threshold},o que se pode fazer é calcular o erro mínimo da imagem de teste com o treinamento, obtido a partir da fórmula \ref{error}, e pode-se calcular utilizando a equação \ref{thresh}. Contudo este valor máximo acaba sendo um valor distante dos demais valores de erros da fórmula \ref{error}, não podendo ser utilizado para a comparação.

\begin{equation}
\label{thresh}
	\theta = 0,8 * max(rast) 
\end{equation}

Com o valor de erro de cada face obtido, foi necessário procurar qual a face que havia obtido o menor erro, os resultdos podem ser observados na Figura \ref{erro_face}

\begin{figure}[htb]
        \centering
        \subfloat[]{
            \begin{minipage}{0.45\linewidth}
              \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{figuras/erro_face_win.png}             
            \end{minipage}} 
        \subfloat[]{
            \begin{minipage}{0.45\linewidth}
             \includegraphics[width=0.98\linewidth, height = 0.2\textheight, keepaspectratio=true]{Figuras/erro_face_lose.png}
            \end{minipage}}     
           \caption{Face de teste, Face reconhecida do banco e Face reconhecida do sistema: (a) Face que foi reconhecida, (b) Face não foi reconhecida}
           \label{erro_face} 
    \end{figure}

A primeira face da Figura \ref{erro_face}(a) é a face que foi utilizada como teste de reconhecimento, a segunda e terceira face são as faces que foram reconhecidas como as que possuiam o menor valor de erro, sendo a segunda obtida do banco de imagens armazenadas no banco de dados e a terceira a armazenada na execução do algoritmo. Porém a Figura \ref{erro_face}(b) mostra uma face de teste que foi reconhecida erroneamente com outra face da base de treinamento.

Dentro dos testes de reconhecimento realizados com o algoritmo, foram utilizados diversas quantidades de eigenfaces, pois segundo \citep{turk2}, utilizar somente as \textit{K} melhores eigenfaces esta diretamente relacionado a eficiência computacional, já que o tamanho do banco de imagens que é utilizada pelo sistema pode aumentar conforme a necessidade de cada sistema. Neste trabalho foram utilizadas 196 imagens para o total da base de treinamento. A Figura \ref{k_win} exemplifica a relação da utilização de \textit{K} para a quantidade de acertos e a Figura \ref{k_lose} a relação de \textit{K} para erros. A quantidade de acertos e erros foram computadas observando manualmente cada imagem do teste com o as imagens da base de treinamento, um exemplo desta validação esta na Figura \ref{erro_face}, onde a imagem era comparada manualmente caso obtivesse um um resultado satisfatório, foi computado como um acerto e caso não como um erro.  

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/k_win.png}
	\caption{Gráfico K x Acertos.}
	\label{k_win}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/k_lose.png}
	\caption{Gráfico K x Erros.}
	\label{k_lose}
\end{figure}

Com os resultados de \textit{K}, observou-se que um dos melhores valores para a utilização para o algoritmo foi o de $K = 70$, sendo assim foram utilizadas as melhores 70 eigenfaces obtidas previamente no processo de reconhecimento.
Os valores dos omegas de cada imagem de teste projetada no espaço de faces, possui um valor de desvio padrão que aparece estar próximo das faces que possuem características semelheantes. O efeito do desvio padrão pode ser notado na Figura \ref{s_omegap}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/s_omegap.png}
	\caption{Desvio Padrão dos Omegas projetados no espaço de faces.}
	\label{s_omegap}
\end{figure}

Este efeito pode ser notado também no desvio padrão das imagens utilizadas no conjunto de treinamento, onde cada face que possui  características semelheantes, acabam tendo um valor mais próximo do outro e fazendo um agrupamento no gráfico da Figura \ref{s_omega}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/s_omega.png}
	\caption{Desvio Padrão dos Omegas no espaço de faces.}
	\label{s_omega}
\end{figure}

\section{Armazenamento}
Dentro do desenvolvimento do trabalho proposto, foi necessário criar um meio de armazenar e recuperar as imagens e valores utilizados pelo sistema. No inicio da aplicação foram utilizadas as imagens localmente, sendo armazenadas e utilizadas somente durante a execução do sistema. Contudo este tipo de solução pode acabar esgotando o armazenamento interno do dispositivo que roda o sistema, sendo assim para que este problema fosse sanado, a forma de armazenamento das informações foi dividdo em duas formas, sendo uma delas para o armazenamento das informações e outra para o armazenamento dos arquivos.
Para o armazenamento das informações foi utilizado o MongoDB com um repositório em nuvem, o seu acesso é feito a partir da biblioteca \textit{Pymongo}, onde cada face tem as seguintes informações armazenadas: 
\begin{itemize}
\item ID do Mongo
\item Nome da Pessoa
\item ID do Google Drive
\end{itemize}
O \textit{ID do Mongo} é um identificador que é gerado automaticamente, sendo uma chave primária igual a de um banco de dados relacional, onde este é um identificador único. O \textit{ID do Google Drive} é o identificador que é gerado automaticamente quando o arquivo com as informações da imagem da face são salvos.

Para o armazenamento de cada imagem foi utilizado o Google Drive, o seu acesso é feito a partir da biblioteca \textit{Pydrive}, onde cada face tem as seguintes infromações armazenadas:
\begin{itemize}
\item Valor de $\Phi$ da face;
\item Valor de $\Omega$ da face.
\end{itemize}
Os valores são armazenados em um arquivo \textit{JSON}, podendo ser utilizadas outras formas de salvar o arquivo, porém foi escolhido o arquivo \textit{JSON} para a facilitação ao acesso das informações, já que as mesmas são armazenadas em formato de lista, sendo mais fácil de fazer a transformação para vetores da biblioteca \textit{Numpy}.

Para o acesso de ambos os bancos é necessário a configuração e utilização de arquivos de configuração, que contenham os usuários e senhas para acesso. Para o acesso do repositório do MongoDB é necessário repassar a linha de conexão do repositório. Para a conexão do Google Drive é necessário a configuração e o aceite na conta do usuário que irá hospedar os arquivos, neste caso foi configurado o arquivo \textit{settings.yaml} para que não fosse necessário abrir uma janela de aceite a cada vez que o sistema fosse executado.

O processo de armazenamento em ambos os bancos ocorre em três etapas, sendo elas: Gerar as informações da face (valores de $\Phi$ e $\Omega$ de cada face individualmente), salvar essas informações no Google Drive e devolver o ID que foi salvo e salvar no Mongo o ID do Gogle Drive juntamente com o nome de cada pessoa. Um exemplo deste processo pode ser notado na Figura \ref{fluxo_banco}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth]{figuras/fluxo_arm.jpg}
	\caption{Recuperação das imagens a partir dos Bancos de Dados.}
	\label{fluxo_banco}
\end{figure}


Para a análise de um nova face, é necessário buscar os valores de cada face no banco de imagens, a forma de busca é feita a partir dos valors de $\Omega$, que foram armazenados previamente, e devolvido o valor de $\Phi$ da face reconhecida (deve-se após receber o valor de $\Phi$ somar o valor de $\Psi$ que também está armazenado no banco de imagens). O método de utilização de ambos os bancos pode ser notado na Figura \ref{recupera_img}
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\textwidth]{figuras/recupera_img.jpg}
	\caption{Recuperação das imagens a partir dos Bancos de Dados.}
	\label{recupera_img}
\end{figure}


\section{Interface}

Para a utilização das eigenfaces, foi desenvolvido uma interface utilizando a biblioteca Tkinter. O objetivo da interface é mostrar para o usuário que a sua face esta sendo capturada e sendo calculado se a sua face será reconhecida, devido ao fato de que as pessoas que serão submetidas ao sistema tem o interesse de serem reconhecidas.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.6\textwidth]{figuras/interface.png}
	\caption{Interface do sistema.}
	\label{interface}
\end{figure}

\chapter{Conclusão} 

\chapter{Trabalhos Futuros}

\bibliography{tcc_template}

%\appendix

%\begin{center}
%\chapter{Detalhes sobre um ítem %específico do trabalho}
%\end{center}	


%\begin{verbatim}	
%apendice
%\end{verbatim}



\end{document}
